# 의미 기반 콘텐츠 문장 추천 시스템 (Semantic Search for Game & Culture Terms)

## ▣ 프로젝트 개요

문화·게임 콘텐츠 용어 데이터를 활용하여  
**특정 용어의 정의와 의미적으로 유사한 문장을 자동 추천**하는  
**자연어 의미 기반 검색 시스템**을 개발하였습니다.

**CNN 임베딩 모델**을 활용해 정의와 문장을 **의미 벡터화**하고,  
**코사인 유사도**를 기준으로 가장 유사한 문장 5개를 실시간 추천합니다.

---

## ▣ 프로젝트 배경 및 목적

- 기존 **키워드 기반 검색은 의미 유사성**을 반영하지 못함  
- 사용자가 **특정 용어를 입력하면**,  
  해당 정의에 가장 적합한 **문장을 자동으로 추천**하는 시스템을 목표로 함  
- **콘텐츠 검색**, **언어 교육**, **자동 용례 추천 시스템** 등에 활용 가능

---

## ▣ 활용 데이터셋

- 출처: **한국콘텐츠진흥원**  
- 구성:
  - `용어.json`: 용어 및 정의  
  - `용례_*.json`: 실제 문장 및 용어 매핑 정보  
- 규모:
  - 학습용: 10,000 문장쌍  
  - 검증용: 2,000 문장쌍

---

## ▣ 프로젝트 진행 과정

### 1. 데이터 전처리 및 토크나이저 구성  
- `KoNLPy`의 `Okt` 사용  
- **명사 추출 중심**의 형태소 분석  
- 불용어 제거 없이 전체 토큰 반영

### 2. CNN 임베딩 모델 설계  
- 구조:  
  `nn.Embedding → Conv1D → AdaptiveMaxPool → Linear`  
- 출력:  
  128차원의 문장 임베딩 벡터

### 3. 문장-정의 간 임베딩 학습  
- 손실함수: `CosineEmbeddingLoss`  
- 정의와 문장이 의미적으로 가까워지도록 훈련  
- `EarlyStopping`으로 과적합 방지

### 4. 웹 서비스 구현 (Streamlit)  
- **사용자 입력**: 용어  
- **출력**: 정의 + 유사 문장 Top 5 자동 추천  
- `vocab.pkl` + `cnn_embedder.pt` 로딩  
- **실시간 벡터 유사도 계산 → 추천 결과 출력**

---

## ▣ 담당 역할

- `semantic_embedder_training.py`  
  → 전체 CNN 임베딩 학습 파이프라인 설계 및 구현  

- `semantic_search_web_app.py`  
  → Streamlit 기반 검색 UI 구현  
  → 입력 → 정의 검색 → 벡터화 → 문장 유사도 계산 → 추천 순 정렬까지 구현

- **모델 및 Vocab 저장 구조 설계**: `joblib`, `torch.save()` 사용  
- 사전 임베딩 캐싱 구조로 **실시간 추천 속도 최적화**

---

## ▣ 분석 결과 요약

| 항목                    | 결과 |
|-------------------------|------|
| 최종 추천 정확도        | 정의-문장 유사성 기준 정확한 Top 5 추천 가능 |
| 실시간 응답 속도        | 빠름 (Streamlit + 캐싱 구조 적용) |
| CNN 임베딩 성능         | 짧은 문장에서 의미 기반 유사도 추정 효과적 |
| Loss 함수 적합성        | `CosineEmbeddingLoss`가 의미 유사 태스크에 매우 적합 |

---

## ▣ 주요 인사이트

- **CNN 구조**만으로도 **문장 의미 임베딩**이 가능하며,  
  특히 **짧은 문장**에서는 정확도와 속도 측면 모두 우수

- `CosineEmbeddingLoss`는 정의-문장 의미 유사도 학습에 최적화되어 있음

- `KoNLPy + PyTorch` 조합으로도 **국문 자연어 처리 시스템** 구축이 가능함을 실증

- 향후 확장 방향:
  - 단어 의미 군집화 (clustering)
  - 비슷한 정의 간 추천
  - **강화 학습 기반 추천 모델**
